{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"text-align: center; font-size: 300%\"> Computational Finance </p>\n",
    "<img src=\"img/ABSlogo.svg\" alt=\"LOGO\" style=\"display:block; margin-left: auto; margin-right: auto; width: 50%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced Monte Carlo Methods\n",
    "## Variance Reduction Techniques\n",
    "* In standard Monte Carlo, the length of the confidence interval for $\\theta\\equiv\\mathbb{E}[X]$ is proportional to $\\hat{\\sigma}/\\sqrt{n}$, where $\\sigma$ is the standard deviation of $X$.\n",
    "* Thus to increase the accuracy by a factor 10 (i.e., gain 1 digit), we need 100 times as many samples.\n",
    "* Variance reduction techniques aim to improve the accuracy of the estimate, without increasing $n$.\n",
    "* We will consider two such techniques: *antithetic sampling*, and *control variates*.\n",
    "* Another powerful technique is *importance sampling*, but this is beyond the scope of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Antithetic Sampling\n",
    "* The crude MC estimate for $\\theta\\equiv \\mathbb{E} [X]$, based on $n$ independent draws $X_i$, is\n",
    "$$\n",
    "\\hat{\\theta}=\\frac{1}{n}\\sum_{i=1}^n X_i,\n",
    "$$\n",
    "* Now suppose that we can somehow sample $n$ pairs $(X_i, \\tilde X_i)$, such that\n",
    "  * both $X_i$ and $\\tilde X_i$ are drawn from the distribution of $X$;\n",
    "  * the *pairs* $(X_i, \\tilde X_i)$ are independent across $i$;\n",
    "  * for each $i$, $X_i$ and $\\tilde X_i$ are (negatively) correlated.\n",
    "* The antithetic variable estimator is then\n",
    "$$\n",
    "\\hat{\\theta}_{AV}=\\frac{1}{2}\\left(\\frac{1}{n}\\sum_{i=1}^n X_i+\\frac{1}{n}\\sum_{i=1}^n \\tilde X_i\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Rewriting the estimator as\n",
    "$$\n",
    "\\hat{\\theta}_{AV}=\\frac{1}{n}\\sum_{i=1}^n\\left(\\frac{X_i+\\tilde X_i}{2}\\right),\n",
    "$$\n",
    "we see that it is unbiased, and that $\\hat{\\theta}_{AV}$ is the mean of $n$ independent observations, $(X_i+\\tilde X_i)/2$, so that the LLN and CLT continue to apply.\n",
    "* Hence, by the CLT,\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\theta}_{AV}-\\theta)\\stackrel d \\rightarrow \\mathrm{N}(0,\\sigma^2_{AV}),\n",
    "$$\n",
    "where\n",
    "\\begin{align*}\n",
    "\\sigma^2_{AV}&\\equiv \\mathrm{var}\\left[\\frac{X_i+\\tilde X_i}{2}\\right]=\\frac{1}{4}\\left(\\mathrm{var}[X_i]+\\mathrm{var}[\\tilde X_i] +2\\mathrm{cov}[X_i,\\tilde X_i]\\right)\\\\\n",
    "%&=\\frac{1}{2}\\left[\\mathrm{var}[X_i] +\\mathrm{cov}[X_i,\\tilde X_i]\\right)\n",
    "&=\\frac{\\sigma^2}{2}\\big(1+\\rho(X_i,\\tilde X_i)\\big).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Comparing the variance of $\\hat{\\theta}_{AV}$, $\\frac{1}{n}\\sigma^2_{AV}$, with that of the crude estimator based on $2n$ observations $\\left(\\frac{1}{2n}\\sigma^2\\right)$, we see that efficiency is gained whenever the correlation $\\rho(X_i,\\tilde X_i)$ is negative.\n",
    "* So how do we draw correlated random numbers $X_i$ and $\\tilde X_i$?\n",
    "* Our simulations are typically based on an array of standard normal random numbers $\\mathbf{z}_i$, i.e., $X_i=f(\\mathbf{z}_i)$. Setting $\\tilde X_i=f(-\\mathbf{z}_i)$ will often do the trick. \n",
    "* Note for standard Brownian motion, this corresponds to flipping the path about the abscissa.\n",
    "* Let's modify last week's `bmsim_vec` and `asianmc_vec` to use antithetic sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def bmsim_vec(T, N, X0=0, mu=0, sigma=1, numsim=1, av=False):\n",
    "    \"\"\"Simulate `numsim` Brownian motion paths. If av=True, then 2*`numsim` paths are returned,\n",
    "    where paths numsim:2numsim+1 are the antithetic paths.\n",
    "    \"\"\"\n",
    "    deltaT = float(T)/N\n",
    "    tvec = np.linspace(0, T, N+1)\n",
    "    z = np.random.randn(numsim, N+1)\n",
    "    if av:\n",
    "        z = np.concatenate((z, -z))\n",
    "    dX = mu*deltaT + sigma*np.sqrt(deltaT)*z\n",
    "    dX[:, 0] = 0.\n",
    "    X = np.cumsum(dX, axis=1)\n",
    "    X += X0    \n",
    "    return tvec, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def asianmc_vec(S0, K, T, r, sigma, delta, N, numsim=1000, av=False):\n",
    "    \"\"\"Monte Carlo price of an arithmetic average Asian call.\n",
    "    Pass `av=True` to use antithetic sampling.\n",
    "    \"\"\"\n",
    "    X0 = np.log(S0)\n",
    "    nu = r-delta-.5*sigma**2    \n",
    "    _, X = bmsim_vec(T, N, X0, nu, sigma, numsim, av)\n",
    "    S = np.exp(X)\n",
    "    payoffs = np.maximum(S[:, 1:].mean(axis=1)-K, 0.)\n",
    "    g = np.exp(-r*T)*payoffs\n",
    "    if av:\n",
    "        g = .5*(g[:numsim]+g[numsim:])    \n",
    "    C = g.mean();s = g.std()\n",
    "    zq = norm.ppf(0.975)\n",
    "    Cl = C - zq/np.sqrt(numsim)*s\n",
    "    Cu = C + zq/np.sqrt(numsim)*s\n",
    "    return C, Cl, Cu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n",
      "0.01\n",
      "0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0927262054551385, 0.03592162508407748)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S0 = 11; K = 10; T = 3/12.; r = 0.02; sigma = .3; delta = 0.01; N = 10; numsim = 10**4\n",
    "np.random.seed(0)\n",
    "C, Cl, Cu = asianmc_vec(S0, K, T, r, sigma, delta, N, numsim, False)\n",
    "C, Cu-Cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0824190804865295, 0.012604081385357624)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "C, Cl, Cu = asianmc_vec(S0, K, T, r, sigma, delta, N, numsim/2, True)\n",
    "C, Cu-Cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Not bad. The new interval is about 1/3 as long, with the same amount of work.\n",
    "* Timings aren't much different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 6.88 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit asianmc_vec(S0, K, T, r, sigma, delta, N, numsim, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.53 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit asianmc_vec(S0, K, T, r, sigma, delta, N, numsim/2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Control Variates\n",
    "* Antithetic sampling is a general technique that requires little knowledge about the system being simulated.\n",
    "* Another variance reduction technique is based on *control variates*. It requires a deeper understanding of the problem, but can yield excellent results.\n",
    "* Suppose again that we want to estimate $\\theta=\\mathbb{E}[X]$.\n",
    "* Further suppose that there is another random variable, $Y$, correlated with $X$, with known mean $\\mathbb{E}[Y]=\\mu$.\n",
    "* Example: $X$ is the discounted payoff on an option. We want to find the price, $\\theta$. $Y$ is the discounted payoff of another option, which can be priced analytically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Suppose we can draw $n$ pairs $(X_i, Y_i)$, i.i.d. across $i$.  The control variate estimator, for a given constant $c$ , is\n",
    "$\n",
    "\\hat{\\theta}_c\\equiv \\bar{X}_n-c(\\bar{Y}_n-\\mu),\n",
    "$\n",
    "where $\\bar{X}_n$ and $\\bar{Y}_n$ are the sample means. Note that\n",
    "$$\n",
    "\\mathbb{E}[\\hat{\\theta}_c]=\\mathbb{E}[\\bar{X}_n]-c\\mathbb{E}[\\bar{Y}_n-\\mu]=\\theta.\\tag{$\\dagger$}\n",
    "$$\n",
    "* Intuition: suppose $X$ and $Y$ are positively correlated and $c>0$. If, due to sampling variation, $\\bar{Y}_n>\\mu$ for a given set of replications, then it is likely that also $\\bar{X}_n>\\theta$, so it should be corrected downwards.\n",
    "* Let $Z_i\\equiv X_i-c(Y_i-\\mu)$. Then\n",
    "$$\n",
    "\\hat{\\theta}_c=\\frac{1}{n}\\sum_{i=1}^n Z_i,\n",
    "$$\n",
    "a sum of $n$ i.i.d. terms, so the LLN and CLT apply. In particular,\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\theta}_c-\\theta)\\stackrel d \\rightarrow \\mathrm{N}(0,\\sigma^2_{CV}),\n",
    "$$\n",
    "where $\\sigma^2_{CV}\\equiv\\mathrm{var}(Z_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* We have that\n",
    "\\begin{align*}\n",
    "\\sigma^2_{CV}&\\equiv\\mathrm{var}(Z_i)=\\mathrm{var}\\big(X_i-c(Y_i-\\mu)\\big)\\\\&=\\sigma^2-2c\\;\\mathrm{cov}(X,Y)+c^2\\mathrm{var}(Y).\n",
    "\\end{align*}\n",
    "* It remains to choose $c$. The optimal $c$ minimizes $\\sigma^2_{CV}$, yielding the FOC\n",
    "$$\n",
    "0=-2\\mathrm{cov}(X,Y)+2c^\\ast\\mathrm{var}(Y)\\quad\\Leftrightarrow\\quad c^\\ast=\\frac{\\mathrm{cov}(X,Y)}{\\mathrm{var}(Y)}.\n",
    "$$\n",
    "* With this choice,\n",
    "$$\n",
    "\\sigma^2_{CV}=\\sigma^2-2\\frac{\\mathrm{cov}^2(X,Y)}{\\mathrm{var}(Y)}+\\frac{\\mathrm{cov}^2(X,Y)}{\\mathrm{var}(Y)},\n",
    "$$\n",
    "or\n",
    "$$\n",
    "\\frac{\\sigma^2_{CV}}{\\sigma^2}=1-\\rho^2(X,Y),\n",
    "$$\n",
    "i.e., the variance is reduced if $\\rho(X,Y)\\neq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* In practice $c^\\ast=\\mathrm{cov}(X,Y)/\\mathrm{var}(Y)$ is unknown and must be estimated.\n",
    "* A consistent estimator is obtained by replacing population moments with sample analogues. This yields $\\hat{c}=S_{X,Y}/S^2_{Y}$.\n",
    "Note that this is the estimated coefficient of $Y$ in a regression of $X$ on $Y$ and a constant.\n",
    "* $\\hat{c}$ is random and not independent of $Y$. In view of $(\\dagger)$, this introduces a bias in $\\hat{\\theta}_{\\hat{c}}$, because we cannot take it out of the expectation. Usually this bias is\n",
    "small (and disappears asymptotically).\n",
    "*  The standard errors (and thus the CI) would also need to be adjusted. We just ignore these difficulties.\n",
    "* The usefulness of the method hinges on the availability of good control variates. A good control variate has $|\\rho(X,Y)|$ close to 1, i.e., a strong linear relationship with $X$. It is possible to incorporate several control variates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Classic example: using the geometric average asian call (which can be priced analytically) as a control variate for an arithmetic average call (which cannot).\n",
    "* The geometric average call has payoff\n",
    "$$\n",
    "C^{\\mathrm{Geo}}_T=\\Big(\\prod_{i=1}^N S_{t_i}^{1/N}-K\\Big)^+=\\exp\\Big(\\frac{1}{N}\\sum_{i=1}^N X_{t_i}-K \\Big)^+, \\qquad X_t\\equiv \\log S_t.\n",
    "$$\n",
    "* Assuming that $t_i=i\\delta t$, it can be shown that \n",
    "$$\n",
    "C^{\\mathrm{Geo}}_0=e^{(\\hat{\\mu}-r)T}S_0\\Phi(\\hat{d}_1)-e^{-rT}K\\Phi(\\hat{d}_2),\n",
    "$$\n",
    "where\n",
    "\\begin{alignat*}{2}\n",
    "\\hat{d}_1&\\equiv\\frac{\\log (S_0/K)+(\\hat{\\mu}+\\frac{1}{2}\\hat{\\sigma}^2)T}{\\hat{\\sigma} \\sqrt{T}}, \\qquad &\\hat{d}_2&\\equiv\\hat{d}_1-\\hat{\\sigma}\\sqrt{T},\\\\\n",
    "\\hat{\\sigma}&\\equiv\\sigma\\sqrt{\\frac{(N+1)(2N+1)}{6N^2}},\\quad\\mbox{and }& \\hat{\\mu}&\\equiv\\frac{\\hat{\\sigma}^2}{2}+\\left(r-\\delta-\\frac{\\sigma^2}{2}\\right)\\frac{N+1}{2N},\n",
    "\\end{alignat*}\n",
    "valid only at the time the option is written; the general formula is more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def asiancall_geo(S0, K, T, r, sigma, delta, N):\n",
    "    \"\"\"Price of a geometric average price asian call.\"\"\"\n",
    "    shat=sigma * np.sqrt(((N+1) * (2*N+1)) / (6.0 * N**2))\n",
    "    mhat=shat**2/2.0 + (r-delta-.5*sigma**2) * (N+1)/(2.0*N)\n",
    "    d1 = (np.log(S0/float(K)) + T*(mhat + 0.5*shat**2)) / shat / np.sqrt(T)\n",
    "    d2 = d1-shat*np.sqrt(T)\n",
    "    return np.exp((mhat-r)*T)*S0*norm.cdf(d1)-np.exp(-r*T)*K*norm.cdf(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asianmc_cv(S0, K, T, r, sigma, delta, N, numsim=1000, av=False):\n",
    "    \"\"\"Monte Carlo price of an arithmetic average Asian call using control variates.\n",
    "    Pass `av=True` to use antithetic sampling.\n",
    "    \"\"\"\n",
    "    X0 = np.log(S0)\n",
    "    nu = r-delta-.5*sigma**2    \n",
    "    _, X = bmsim_vec(T, N, X0, nu, sigma, numsim, av)\n",
    "    S = np.exp(X)\n",
    "    mu = asiancall_geo(S0, K, T, r, sigma, delta, N)\n",
    "    payoffs = np.maximum(S[:, 1:].mean(axis=1)-K, 0.)\n",
    "    control = np.maximum(np.exp(X[:, 1:].mean(axis=1))-K, 0.)\n",
    "    c = (np.cov(payoffs, control)/np.var(control))[0, 1]\n",
    "    g = np.exp(-r*T)*payoffs - c*(np.exp(-r*T)*control-mu)\n",
    "    if av:\n",
    "        g = .5*(g[:numsim]+g[numsim:])    \n",
    "    C = g.mean();s = g.std()\n",
    "    zq = norm.ppf(0.975)\n",
    "    Cl = C - zq/np.sqrt(numsim)*s\n",
    "    Cu = C + zq/np.sqrt(numsim)*s\n",
    "    return C, Cl, Cu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2647179219553755, 5.2874996563367915e-06)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "C, Cl, Cu = asianmc_cv(S0, K, T, r, sigma, delta, 1, numsim, False)\n",
    "C, Cu-Cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wow. We can even combine it with antithetic sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2647182412456213, 2.684124061680393e-06)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "C, Cl, Cu = asianmc_cv(S0, K, T, r, sigma, delta, 1, numsim/2, True)\n",
    "C, Cu-Cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This again slashes the length of the confidence interval in half (not that it matters at this point). Obviously the two payoffs are very highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Timings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 6.19 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit asianmc_vec(S0, K, T, r, sigma, delta, N, numsim, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 6.86 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit asianmc_cv(S0, K, T, r, sigma, delta, N, numsim, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.08 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit asianmc_cv(S0, K, T, r, sigma, delta, N, numsim/2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Strangely, this time around using antithetic sampling actually makes the code run faster. Talk about a free lunch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Expat Conundrum: Greeks in Monte Carlo\n",
    "* So far we were mostly concerned with *pricing* options. An equally important problem in practice is *hedging*.\n",
    "Suppose that a financial institution has issued a call option (i.e., it is short the option). In order to eliminate the risk, it might create the hedge\n",
    "$$\n",
    "\\Pi _{t}=-C_{t}+\\phi _{t}S_{t},\n",
    "$$\n",
    "where $\\phi_{t}$ is a number of stocks. The *delta-hedged* portfolio has\n",
    "$$\n",
    "\\phi _{t}=\\Delta_t:=\\frac{\\partial C_{t}}{\\partial S_{t}}.\n",
    "$$\n",
    "* This position is *delta-neutral*: it is immune to (infinitesimally) small movements of the underlying.\n",
    "* The portfolio has to be adjusted every time the underlying moves (because $\\Delta_t$ depends on time), incurring trading costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* If there is another instrument on the same underlying available, then it is possible to construct a portfolio that is also *gamma-neutral*. Gamma is defined as\n",
    "$$\n",
    "\\Gamma_t=\\frac{\\partial^2 C_{t}}{\\partial S^2_{t}}.\n",
    "$$\n",
    "Such a portfolio may need to be readjusted less frequently.\n",
    "* $\\Delta_t$ and $\\Gamma_t$ are examples of the so-called option *Greeks*. Other examples are $\\theta_t$ (the derivative with respect to time), $\\rho_t$ (w.r.t. $r$), and $\\mathcal{V}_t$ (\"Vega\", w.r.t. $\\sigma$).\n",
    "* In the BS model, the latter two parameters are constant, but in practice they are not.\n",
    "* In order to construct a hedge, it is important that we be able to compute the Greeks. This is easy if we have an analytical expression for the price; e.g., for a European call in the BS model, it can be shown\n",
    "that\n",
    "$$\n",
    "\\Delta_t=e^{-\\delta(T-t)}\\Phi(d_1).\n",
    "$$\n",
    "Chapter 18 of Hull (2012) lists the expressions for the other Greeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* If the option cannot be priced analytically, then we may need to resort to Monte Carlo.\n",
    "* Recalling our risk neutral pricing formula,\n",
    "$$\n",
    "\\Delta_0\\equiv\\frac{\\partial}{\\partial S_0} \\mathbb{E}^{\\mathbb{Q}}\\left[e^{-rT}C_T(S_0)\\right].\n",
    "$$\n",
    "* In view of the definition of the derivative,\n",
    "$$\n",
    "\\Delta_0= \\lim_{\\delta S_0\\rightarrow 0} \\frac{\\mathbb{E}^{\\mathbb{Q}}\\left[e^{-rT}C_T(S_0+\\delta S_0)\\right]-\\mathbb{E}^{\\mathbb{Q}}\\left[e^{-rT}C_T(S_0)\\right]}{\\delta S_0},\n",
    "$$\n",
    "it is natural to approximate $\\Delta_0$ with a finite difference quotient for some small $\\delta S_0$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82029812351485099"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dS=.01 \n",
    "np.random.seed(0)\n",
    "Cd, _, _ = asianmc_vec(S0+dS, K, T, r, sigma, delta, N, numsim)\n",
    "C,  _, _ = asianmc_vec(S0,    K, T, r, sigma, delta, N, numsim)\n",
    "Delta=(Cd-C)/dS; Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The true answer is around 0.858."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " * Let's try to improve the approximation by reducing $\\delta S_0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46612493142594857"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dS=.001; np.random.seed(0)\n",
    "Cd, _, _ = asianmc_vec(S0+dS, K, T, r, sigma, delta, N, numsim)\n",
    "C,  _, _ = asianmc_vec(S0,    K, T, r, sigma, delta, N, numsim)\n",
    "Delta=(Cd-C)/dS; Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ouch.\n",
    "* What's happeing is that the sampling variation in $C_T$ dominates the variation from a small perturbation of $S_0$. This increases the variance of the estimator (which is nevertheless unbiased).\n",
    "* The trick is to use the same random numbers in both simulation runs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85853256159129643"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dS=.001; np.random.seed(0)\n",
    "Cd, _, _ = asianmc_vec(S0+dS, K, T, r, sigma, delta, N, numsim)\n",
    "np.random.seed(0)\n",
    "C,  _, _ = asianmc_vec(S0,    K, T, r, sigma, delta, N, numsim)\n",
    "Delta=(Cd-C)/dS; Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Essentially, the method of common random numbers amounts to the approximation\n",
    "$$\n",
    "\\Delta_0\\approx \\mathbb{E}^{\\mathbb{Q}}\\left[\\frac{e^{-rT}C_T(S_0+\\delta S_0)-e^{-rT}C_T(S_0)}{\\delta S_0}\\right].\n",
    "$$\n",
    "* The validity of this approach hinges on whether it is justified to take the limit in the above expression, i.e., whether we may exchange the order of derivative and expectation so that\n",
    "$$\n",
    "\\frac{\\partial}{\\partial S_0} \\mathbb{E}^{\\mathbb{Q}}\\left[e^{-rT}C_T(S_0)\\right]= \\mathbb{E}^{\\mathbb{Q}}\\left[\\frac{\\partial}{\\partial S_0} e^{-rT}C_T(S_0)\\right].\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "livereveal": {
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
